{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57516d8-1607-4573-bcdd-c78af6861c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from currensee.agents.complete_graph import compiled_graph\n",
    "from currensee.agents.tools.finance_tools import generate_macro_table\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382d110-7666-4cf9-8664-a6ec2799f35e",
   "metadata": {},
   "source": [
    "## Define Initial State\n",
    "\n",
    "This is data that we should be retrieving from each meeting invite.\n",
    "\n",
    "**DO NOT** change this data until the CRM DB has been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4c7df-7a99-4862-b4ff-e84ed8dfc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = {\n",
    "    \"client_name\": \"Adam Clay\",\n",
    "    \"client_email\": \"adam.clay@compass.com\",\n",
    "    \"meeting_timestamp\": \"2024-03-26 11:00:00\",\n",
    "    \"meeting_description\": \"Compass - Annual Credit Facility Review Meeting\",\n",
    "    \"report_length\": \"long\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71339a6-c098-47df-bb6d-acb6bcb1dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = compiled_graph.invoke(init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae11b7-32be-4660-b462-69fb01173a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = result[\"final_summary\"]\n",
    "\n",
    "# === Add the macro snapshot\n",
    "macro_table = generate_macro_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200286f-fc4e-4de0-bbc9-df9486c1cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_report = summary  # + \"\\n\\n### Macro Financial Snapshot\\n\\n\" + macro_table\n",
    "print(full_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1f39b-e207-475f-bc60-94c89708b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceback\n",
    "\n",
    "client_industry_summary = result.get(\"client_industry_sources\", [])\n",
    "macro_news_summary = result.get(\"macro_news_sources\", [])\n",
    "\n",
    "\n",
    "# Function to format and print client_industry and macro_news summaries\n",
    "def print_summary(summary, summary_name):\n",
    "    print(f\"\\n{summary_name}:\\n{'='*len(summary_name)}\")\n",
    "    for article in summary:\n",
    "        title = article.get(\"title\", \"No Title\")\n",
    "        snippet = article.get(\"snippet\", \"No Snippet\")\n",
    "        date = article.get(\"date\", \"No Date\")\n",
    "        link = article.get(\"link\", \"\")\n",
    "\n",
    "        # Extract the source from the domain of the link\n",
    "        source = link.split(\"/\")[2] if link else \"No Source\"\n",
    "\n",
    "        # Format and print the information\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Snippet: {snippet}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Source: {source}\")\n",
    "        print(f\"Link: {link}\")  # Displaying the full link\n",
    "        print(\"-\" * 40)  # Just a separator for readability\n",
    "\n",
    "\n",
    "# Function to format and print the holdings summary\n",
    "def print_holdings_summary(holdings_sources):\n",
    "    print(\"\\nClient Holdings Summary:\")\n",
    "    print(\"========================\")\n",
    "\n",
    "    for holding, articles in holdings_sources.items():\n",
    "        print(f\"\\n--- {holding} ---\")\n",
    "        if not articles:\n",
    "            print(\"No news found.\")\n",
    "            continue\n",
    "\n",
    "        for article in articles:\n",
    "            title = article.get(\"title\", \"No Title\")\n",
    "            snippet = article.get(\"snippet\", \"No Snippet\")\n",
    "            date = article.get(\"date\", \"No Date\")\n",
    "            link = article.get(\"link\", \"\")\n",
    "            source = link.split(\"/\")[2] if link else \"No Source\"\n",
    "\n",
    "            print(f\"Title: {title}\")\n",
    "            print(f\"Snippet: {snippet}\")\n",
    "            print(f\"Date: {date}\")\n",
    "            print(f\"Source: {source}\")\n",
    "            print(f\"Link: {link}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# Print the formatted summaries\n",
    "# print_summary(client_industry_summary, 'Client Industry Summary')\n",
    "# print_summary(macro_news_summary, 'Macro News Summary')\n",
    "# print_holdings_summary(result.get(\"client_holdings_sources\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1faebb0-baea-4104-8945-5097ff593ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "from currensee.core import get_model, settings\n",
    "\n",
    "\n",
    "def chunk_sources_with_metadata(\n",
    "    sources: dict[str, list[dict]], max_length: int = 1000\n",
    ") -> dict[str, tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Chunk each source's snippet and retain the original link with each chunk.\n",
    "    Returns a dict like { 'Client Industry Summary [1.1]': (chunk_text, source_url) }\n",
    "    \"\"\"\n",
    "    chunked = {}\n",
    "    for category, entries in sources.items():\n",
    "        for i, entry in enumerate(entries):\n",
    "            snippet = entry.get(\"snippet\", \"\")\n",
    "            link = entry.get(\"link\", \"\")\n",
    "            title = entry.get(\"title\", \"\")\n",
    "\n",
    "            full_text = f\"{title}\\n{snippet}\".strip()\n",
    "            chunks = wrap(\n",
    "                full_text, max_length, break_long_words=False, replace_whitespace=False\n",
    "            )\n",
    "\n",
    "            for j, chunk in enumerate(chunks):\n",
    "                key = f\"{category} [{i+1}.{j+1}]\"\n",
    "                chunked[key] = (chunk.strip(), link)\n",
    "    return chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec688ed0-bf3c-44dd-b66e-9664b09796b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_with_urls(\n",
    "    summary: str, chunked_sources: dict[str, tuple[str, str]]\n",
    ") -> str:\n",
    "    formatted_sources = \"\\n\\n\".join(\n",
    "        f\"{key} (Source: {url}):\\n{chunk}\"\n",
    "        for key, (chunk, url) in chunked_sources.items()\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a financial analyst assistant. You generated the following summary:\n",
    "\n",
    "--- Summary ---\n",
    "{summary}\n",
    "\n",
    "You used these source snippets (each with its original URL):\n",
    "\n",
    "--- Sources ---\n",
    "{formatted_sources}\n",
    "\n",
    "Please map each claim from the summary to the URLs that support it. Format:\n",
    "\n",
    "- Summary claim: \"...\"\n",
    "  → Source URL(s): [\"https://...\"]\n",
    "\n",
    "Use only the URLs in the provided sources. Don't invent URLs.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_holdings_sources(raw_sources):\n",
    "    if not raw_sources:\n",
    "        return []\n",
    "\n",
    "    formatted = []\n",
    "    for ticker, articles in raw_sources.items():\n",
    "        for article in articles:\n",
    "            formatted.append(\n",
    "                {\n",
    "                    \"title\": article.get(\"title\", ticker),\n",
    "                    \"snippet\": article.get(\"snippet\", \"\"),\n",
    "                    \"link\": article.get(\"link\", \"\"),\n",
    "                }\n",
    "            )\n",
    "    return formatted\n",
    "\n",
    "\n",
    "# Step 1: Get and chunk sources properly\n",
    "sources = {\n",
    "    \"Client Industry Summary\": result.get(\"client_industry_sources\", []),\n",
    "    \"Holdings Summary\": format_holdings_sources(\n",
    "        result.get(\"client_holdings_sources\", {})\n",
    "    ),\n",
    "    \"Macro Summary\": result.get(\"macro_news_sources\", []),\n",
    "}\n",
    "\n",
    "chunked_sources = chunk_sources_with_metadata(sources)\n",
    "\n",
    "# Step 2: Compose prompt and ask LLM\n",
    "prompt = build_prompt_with_urls(summary, chunked_sources)\n",
    "\n",
    "# Step 3: Invoke LLM\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = get_model(settings.DEFAULT_MODEL)\n",
    "response = model.invoke([HumanMessage(content=prompt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2d2fe-bd62-4760-9871-6e7b6adeb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# Step 3.5: Filter the output to remove claims with no supporting URLs\n",
    "def filter_empty_sources(response_text: str) -> str:\n",
    "    # Split the output into individual claim blocks\n",
    "    claim_blocks = re.split(r\"\\n(?=- Summary claim:)\", response_text.strip())\n",
    "\n",
    "    # Keep only those blocks that contain at least one URL\n",
    "    filtered_blocks = [\n",
    "        block\n",
    "        for block in claim_blocks\n",
    "        if not re.search(r\"→ Source URL\\(s\\):\\s*\\[\\s*\\]\\s*(\\*.*\\*)?\", block)\n",
    "    ]\n",
    "\n",
    "    return \"\\n\\n\".join(filtered_blocks)\n",
    "\n",
    "\n",
    "def extract_claim_url_pairs(response_text: str) -> list[tuple[str, list[str]]]:\n",
    "    \"\"\"\n",
    "    Extracts a list of (claim, urls) from the LLM's response.\n",
    "    \"\"\"\n",
    "    claim_url_pairs = []\n",
    "    blocks = re.findall(\n",
    "        r'- Summary claim:\\s*\"(.*?)\"\\s*→ Source URL\\(s\\):\\s*(\\[.*?\\])',\n",
    "        response_text,\n",
    "        re.DOTALL,\n",
    "    )\n",
    "    for claim, urls_str in blocks:\n",
    "        try:\n",
    "            urls = eval(urls_str, {\"__builtins__\": None}, {})\n",
    "            if isinstance(urls, list) and all(isinstance(u, str) for u in urls):\n",
    "                claim_url_pairs.append((claim.strip(), urls))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return claim_url_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf1848-946a-4cfb-9919-9207416f9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def insert_links_into_summary(summary: str, claim_url_pairs: list[tuple[str, list[str]]]) -> str:\n",
    "#     \"\"\"\n",
    "#     Inserts Markdown-style [Source] links after corresponding claims in the summary.\n",
    "#     \"\"\"\n",
    "#     updated_summary = summary\n",
    "\n",
    "#     for claim, urls in claim_url_pairs:\n",
    "#         if len(urls) == 1:\n",
    "#             link_text = f\" ([Source]({urls[0]}))\"\n",
    "#         else:\n",
    "#             link_text = \" (\" + \", \".join(\n",
    "#                 f\"[Source {i+1}]({url})\" for i, url in enumerate(urls)\n",
    "#             ) + \")\"\n",
    "\n",
    "#         # Escape regex special characters in the claim text\n",
    "#         pattern = re.escape(claim)\n",
    "#         replacement = f'{claim}{link_text}'\n",
    "\n",
    "#         updated_summary, count = re.subn(pattern, replacement, updated_summary, count=1)\n",
    "#         if count == 0:\n",
    "#             print(f\"⚠️ Could not find claim in summary: '{claim}'\")\n",
    "\n",
    "#     return updated_summary\n",
    "\n",
    "\n",
    "def insert_links_into_summary(\n",
    "    summary: str, claim_url_pairs: list[tuple[str, list[str]]]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Inserts Markdown-style [Source] links after corresponding claims in the summary.\n",
    "    Only includes up to 3 sources per claim (truncates any extra).\n",
    "    \"\"\"\n",
    "    updated_summary = summary\n",
    "\n",
    "    for claim, urls in claim_url_pairs:\n",
    "        truncated_urls = urls[:3]  # ⛔ Truncate to at most 3 URLs\n",
    "\n",
    "        if len(truncated_urls) == 1:\n",
    "            link_text = f\" ([Source]({truncated_urls[0]}))\"\n",
    "        else:\n",
    "            link_text = (\n",
    "                \" (\"\n",
    "                + \", \".join(\n",
    "                    f\"[Source {i+1}]({url})\" for i, url in enumerate(truncated_urls)\n",
    "                )\n",
    "                + \")\"\n",
    "            )\n",
    "\n",
    "        pattern = re.escape(claim)\n",
    "        replacement = f\"{claim}{link_text}\"\n",
    "\n",
    "        updated_summary, count = re.subn(pattern, replacement, updated_summary, count=1)\n",
    "        if count == 0:\n",
    "            print(f\"⚠️ Could not find claim in summary: '{claim}'\")\n",
    "\n",
    "    return updated_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755652f8-9691-440d-bf4e-62c95fc06688",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "filtered_output = filter_empty_sources(response.content)\n",
    "claim_url_pairs = extract_claim_url_pairs(filtered_output)\n",
    "linked_summary = insert_links_into_summary(summary, claim_url_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5969e5-3294-4a60-aa49-75356207414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from weasyprint import HTML\n",
    "\n",
    "\n",
    "def convert_markdown_links_to_html(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts markdown-style links like [Source 1](https://example.com)\n",
    "    into <a href=\"https://example.com\">Source 1</a>\n",
    "    \"\"\"\n",
    "    return re.sub(\n",
    "        r\"\\[([^\\]]+)\\]\\((https?://[^\\)]+)\\)\",\n",
    "        r'<a href=\"\\2\" target=\"_blank\" rel=\"noopener noreferrer\">\\1</a>',\n",
    "        text,\n",
    "    )\n",
    "\n",
    "\n",
    "def wrap_html(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Wraps converted content in full HTML with proper styling.\n",
    "    \"\"\"\n",
    "    html_body = content.replace(\"\\n\", \"<br>\")\n",
    "    return f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\">\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: Arial, sans-serif;\n",
    "                font-size: 14px;\n",
    "                line-height: 1.6;\n",
    "                color: #000;\n",
    "                padding: 40px;\n",
    "            }}\n",
    "            a {{\n",
    "                color: #0645AD;\n",
    "                text-decoration: underline;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        {html_body}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def generate_pdf_from_summary(\n",
    "    linked_summary: str, output_file: str = \"final_summary.pdf\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts markdown-like [Source](url) links to HTML, wraps it, and writes a working PDF.\n",
    "    \"\"\"\n",
    "    html_links = convert_markdown_links_to_html(linked_summary)\n",
    "    full_html = wrap_html(html_links)\n",
    "    HTML(string=full_html, base_url=\".\").write_pdf(output_file)\n",
    "    print(f\"✅ PDF created: {output_file}\")\n",
    "\n",
    "\n",
    "generate_pdf_from_summary(linked_summary, \"final_summary.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42660f43-25a1-4372-9d18-42511e49601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def insert_links_into_summary_html(summary: str, claim_url_pairs: list[tuple[str, list[str]]]) -> str:\n",
    "#     \"\"\"\n",
    "#     Inserts HTML-style <a> links after claims and returns a fully HTML-formatted summary.\n",
    "#     \"\"\"\n",
    "#     updated_summary = summary\n",
    "\n",
    "#     for claim, urls in claim_url_pairs:\n",
    "#         if len(urls) == 1:\n",
    "#             link_text = f' (<a href=\"{urls[0]}\" target=\"_blank\" rel=\"noopener noreferrer\" title=\"\">Source</a>)'\n",
    "#         else:\n",
    "#             link_text = \" (\" + \", \".join(\n",
    "#                 f'<a href=\"{url}\" target=\"_blank\" rel=\"noopener noreferrer\" title=\"\">Source {i+1}</a>'\n",
    "#                 for i, url in enumerate(urls)\n",
    "#             ) + \")\"\n",
    "\n",
    "#         pattern = re.escape(claim)\n",
    "#         replacement = f'{claim}{link_text}'\n",
    "\n",
    "#         updated_summary, count = re.subn(pattern, replacement, updated_summary, count=1)\n",
    "#         if count == 0:\n",
    "#             print(f\"⚠️ Could not find claim in summary: '{claim}'\")\n",
    "\n",
    "#     return updated_summary\n",
    "\n",
    "# def format_html_paragraphs(text: str) -> str:\n",
    "#     lines = text.strip().split(\"\\n\")\n",
    "#     html_lines = []\n",
    "#     for line in lines:\n",
    "#         if line.startswith(\"* \"):\n",
    "#             html_lines.append(f\"<li>{line[2:]}</li>\")\n",
    "#         elif line.strip().startswith(\"**\") and line.strip().endswith(\"**\"):\n",
    "#             html_lines.append(f\"<h3>{line.strip('* ')}</h3>\")\n",
    "#         elif line.strip() == \"\":\n",
    "#             html_lines.append(\"<br>\")\n",
    "#         else:\n",
    "#             html_lines.append(f\"<p>{line.strip()}</p>\")\n",
    "#     return \"\\n\".join(html_lines)\n",
    "# linked_summary = insert_links_into_summary_html(summary, claim_url_pairs)\n",
    "# final_html = format_html_paragraphs(linked_summary)\n",
    "\n",
    "# with open(\"annotated_summary.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(f\"<html><body>{final_html}</body></html>\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-so_currensee-so_currensee",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "so_currensee",
   "language": "python",
   "name": "conda-env-so_currensee-so_currensee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
