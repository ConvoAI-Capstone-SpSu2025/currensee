{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc7edf7-ab52-402a-9a2f-180423c151a8",
   "metadata": {},
   "source": [
    "# Sample CloudSql Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e41979-b411-4577-a8e0-4a4dbdee0f98",
   "metadata": {},
   "source": [
    "# Need to set up for each instance - Add your VM's IP to the Authorized Networks\n",
    "**1. Find the external IP of your JupyterLab VM**\n",
    "https://console.cloud.google.com/compute/instances?project=adsp-34002-on02-sopho-scribe&authuser=1\n",
    " * Go to VM Instances\n",
    " * Find your JupyterLab VM\n",
    " * Copy the External IP address (looks like 34.91.100.45).\n",
    "\n",
    "**2. Add the VM's IP to your Cloud SQL authorized networks**\n",
    "https://console.cloud.google.com/sql/instances/currensee-sql/connections/networking?authuser=1&project=adsp-34002-on02-sopho-scribe\n",
    "* Go to Cloud SQL instances. \n",
    "* Click your instance.\n",
    "* Click Connections in the left sidebar.\n",
    "* Scroll to Authorized networks â†’ Add network.\n",
    "* Name: anything like jupyterlab-vm\n",
    "* Network: paste the external IP you just copied (e.g., 34.91.100.45/32)\n",
    "* IMPORTANT: Add /32 to allow only that single IP.\n",
    "* Click Save.\n",
    "\n",
    "It will take ~30 seconds to update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c777fa9-44e9-4f00-a6ba-ea9f5eb39497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%poetry add -q google-cloud-secret-manager==2.23.3\n",
    "#%poetry add -q SQLAlchemy==2.0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac245ba5-c8af-4df4-bd49-140e68d41439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%poetry add psycopg2-binary sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ca0f95-d1f8-487e-b9b2-abdf685f19cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import secretmanager\n",
    "import pandas as pd\n",
    "from currensee.utils.db_utils import create_pg_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197965a0-ce47-474b-9ade-2f6f068a81e5",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "The cell below will only work if you have a .env file defined at `<fl>_currensee/currensee/.env` with the credentials \n",
    "defined in `<fl>_currensee/currensee/.env.example`.\n",
    "\n",
    "Instructions are located within the `.env.example` file with how to fill out the credentials properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb578b85-e907-48cb-9807-c0787910c2e0",
   "metadata": {},
   "source": [
    "#### Create SQLAlchemy engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110acfc0-b745-4dad-9a74-3c84533305f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DB_NAME\n",
    "DB_NAME = 'crm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815feba1-4fa8-4807-aacc-a9e383812cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m engine = \u001b[43mcreate_pg_engine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m   \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDB_NAME\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lc_currensee/currensee/currensee/utils/db_utils.py:13\u001b[39m, in \u001b[36mcreate_pg_engine\u001b[39m\u001b[34m(db_name)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_pg_engine\u001b[39m(db_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     engine = \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPOSTGRES_ENGINE_STR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdb_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconnect_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msslmode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrequire\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m, in \u001b[36mcreate_engine\u001b[39m\u001b[34m(url, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/lc_currensee/lib/python3.11/site-packages/sqlalchemy/util/deprecations.py:281\u001b[39m, in \u001b[36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[39m\u001b[34m(fn, *args, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    275\u001b[39m         _warn_with_version(\n\u001b[32m    276\u001b[39m             messages[m],\n\u001b[32m    277\u001b[39m             versions[m],\n\u001b[32m    278\u001b[39m             version_warnings[m],\n\u001b[32m    279\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    280\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/lc_currensee/lib/python3.11/site-packages/sqlalchemy/engine/create.py:602\u001b[39m, in \u001b[36mcreate_engine\u001b[39m\u001b[34m(url, **kwargs)\u001b[39m\n\u001b[32m    600\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    601\u001b[39m             dbapi_args[k] = pop_kwarg(k)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m     dbapi = \u001b[43mdbapi_meth\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdbapi_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    604\u001b[39m dialect_args[\u001b[33m\"\u001b[39m\u001b[33mdbapi\u001b[39m\u001b[33m\"\u001b[39m] = dbapi\n\u001b[32m    606\u001b[39m dialect_args.setdefault(\u001b[33m\"\u001b[39m\u001b[33mcompiler_linting\u001b[39m\u001b[33m\"\u001b[39m, compiler.NO_LINTING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/lc_currensee/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py:696\u001b[39m, in \u001b[36mPGDialect_psycopg2.import_dbapi\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    694\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimport_dbapi\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\n\u001b[32m    698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m psycopg2\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "engine = create_pg_engine(\n",
    "   db_name=DB_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811328be-20fd-4c30-883a-3e54f21c253a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_result = pd.read_sql(\u001b[33m\"\u001b[39m\u001b[33mSELECT * FROM Employees limit 10\u001b[39m\u001b[33m\"\u001b[39m, con=\u001b[43mengine\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_result)\n",
      "\u001b[31mNameError\u001b[39m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "df_result = pd.read_sql(\"SELECT * FROM Employees limit 10\", con=engine)\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd163765-fccf-4303-b6ab-ed3a3b670218",
   "metadata": {},
   "source": [
    "# Generate Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f230b65-b7f2-4846-91c8-a421c5125a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %poetry add faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73695d8-97ab-47c4-9aaa-7d0ed8e20996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker instance\n",
    "#Faker is a Python package that integrates fake data for you.\n",
    "\n",
    "#Some hard coded data of publicly traded companies to be our mock clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364c2e8-a811-4f72-a217-9d812829249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Helper function to generate synthetic employee data\n",
    "def generate_employee_data(num_employees=10, ourcompany_name = 'bankwell'):\n",
    "    Company = ourcompany_name\n",
    "    employees = [\n",
    "        {\n",
    "            'EmployeeID': fake.unique.uuid4(),\n",
    "            'FirstName': \"Jane\",\n",
    "            'LastName': \"Moneypenny\",\n",
    "            'Title': \"Relationship Manager\",\n",
    "            'Email': \"jane.moneypenny1@bankwell.com\",\n",
    "            'Phone': fake.phone_number(),\n",
    "            'HireDate': fake.date_this_decade(),\n",
    "            'Department': 'Enterprise Investment',\n",
    "            'Market': 'San Fransisco'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for _ in range(num_employees-1):\n",
    "        EmployeeID = fake.unique.uuid4()\n",
    "        FirstName = fake.first_name()\n",
    "        LastName = fake.last_name()\n",
    "        Title = random.choice(['Finance Assistant', 'Financial Advisor', 'Senior Relationship Manager', 'Product Specialist', 'Relationship Manager'])\n",
    "        Phone = fake.phone_number()\n",
    "        Department = random.choice(['Enterprise Investment', 'Small Business Investment', 'Operations', 'Sales', 'Customer Support'])\n",
    "        HireDate = fake.date_this_decade()\n",
    "        Market = random.choice(['San Fransisco', 'New York City', 'Boston', 'Denver', 'Los Angeles', 'Miami', 'Washington DC', 'Seattle', 'Dallas', 'Chicago'])\n",
    "        Company_clean = re.sub(r'\\W+', '', Company).lower()\n",
    "        Email = f\"{FirstName.lower()}.{LastName.lower()}@{Company_clean}.com\"\n",
    "\n",
    "\n",
    "        employees.append({\n",
    "            'EmployeeID': EmployeeID,\n",
    "            'FirstName': FirstName,\n",
    "            'LastName': LastName,\n",
    "            'Title': Title,\n",
    "            'Email': Email,\n",
    "            'Phone': Phone,\n",
    "            'HireDate': HireDate,\n",
    "            'Department': Department,\n",
    "            'Market': Market\n",
    "        })\n",
    "    return pd.DataFrame(employees)\n",
    "\n",
    "# Helper function to generate point of contact and info for a Company\n",
    "def generate_point_of_contact(Company_name):\n",
    "    AccountID = fake.unique.uuid4()\n",
    "    FirstName = fake.first_name()\n",
    "    LastName = fake.last_name()\n",
    "    ContactTitle = random.choice([\"Senior Director\", \"Manager\", \"Director\", \"VP\", \"Consultant\"])\n",
    "    Phone = fake.phone_number()\n",
    "    Website = fake.url()\n",
    "    Location = random.choice(['San Fransisco', 'New York City', 'Boston', 'Denver', 'Los Angeles', 'Miami', 'Washington DC', 'Seattle', 'Dallas', 'Chicago'])\n",
    "    AnnualRevenue = random.randint(1000000, 50000000)\n",
    "    TotalAccountBal = random.randint(1000000, 50000000)\n",
    "\n",
    "    # Clean Company name for use in email\n",
    "    Company_clean = re.sub(r'\\W+', '', Company_name).lower()\n",
    "    Email = f\"{FirstName.lower()}.{LastName.lower()}@{Company_clean}.com\"\n",
    "\n",
    "    return {\n",
    "        \"AccountID\": AccountID,\n",
    "        \"ContactFirstName\": FirstName,\n",
    "        \"ContactLastName\": LastName,\n",
    "        \"ContactTitle\": ContactTitle,\n",
    "        \"Phone\": Phone,\n",
    "        \"Email\": Email,\n",
    "        \"Website\": Website,\n",
    "        \"Location\": Location,\n",
    "        \"AnnualRevenue\": AnnualRevenue,\n",
    "        \"TotalAccountBal\": TotalAccountBal\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_account_data(num_accounts=5, clients_company = []):\n",
    "# Build the data\n",
    "    accounts = []\n",
    "    for company in clients_company:\n",
    "        contact = generate_point_of_contact(company[\"Company\"])\n",
    "        record = {\n",
    "          \"Company\": company[\"Company\"],\n",
    "          \"industry\": company[\"industry\"],\n",
    "          **contact\n",
    "      }\n",
    "        accounts.append(record)\n",
    "    return pd.DataFrame(accounts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Helper function to generate synthetic opportunity data\n",
    "def generate_opportunity_data(accounts_df, num_opportunities_per_account=3):\n",
    "    opportunities = []\n",
    "    for _, account in accounts_df.iterrows():\n",
    "        num_opportunities = random.randint(1, num_opportunities_per_account)\n",
    "        for _ in range(num_opportunities):\n",
    "            opportunities.append({\n",
    "                'OpportunityID': fake.unique.uuid4(),\n",
    "                'AccountID': account['AccountID'],\n",
    "                'OpportunityName': fake.bs(),\n",
    "                'Stage': random.choice(['Prospecting', 'Qualification', 'Proposal', 'Negotiation', 'Won', 'Lost', 'Closed']),\n",
    "                'Type': random.choice(['New Business', 'Existing Business', 'Renewal', 'Upsell']),\n",
    "                'CloseDate': fake.date_this_year(),\n",
    "                'Amount': random.randint(50000, 500000),\n",
    "            })\n",
    "    return pd.DataFrame(opportunities)\n",
    "\n",
    "# Helper function to generate synthetic employee-contact relationship data\n",
    "def generate_employee_contact_data(employees_df, accounts_df, num_relationships_per_employee=2):\n",
    "    relationships = []\n",
    "    for _, employee in employees_df.iterrows():\n",
    "        num_relationships = random.randint(1, num_relationships_per_employee)\n",
    "        for _ in range(num_relationships):\n",
    "            account = random.choice(accounts_df['AccountID'].tolist())\n",
    "            relationships.append({\n",
    "                'EmployeeID': employee['EmployeeID'],\n",
    "                'EmployeeFirstName': employee['FirstName'],\n",
    "                'EmployeeLastName': employee['LastName'],\n",
    "                'AccountID': account,\n",
    "                'Company': accounts_df.loc[accounts_df['AccountID'] == account, 'Company'].iloc[0],\n",
    "                'Industry': accounts_df.loc[accounts_df['AccountID'] == account, 'industry'].iloc[0],\n",
    "                'ContactFirstName': accounts_df.loc[accounts_df['AccountID'] == account, 'ContactFirstName'].iloc[0],\n",
    "                'ContactLastName': accounts_df.loc[accounts_df['AccountID'] == account, 'ContactLastName'].iloc[0],\n",
    "                'ContactEmail': accounts_df.loc[accounts_df['AccountID'] == account, 'Email'].iloc[0],\n",
    "                'ContactTitle': accounts_df.loc[accounts_df['AccountID'] == account, 'ContactTitle'].iloc[0],\n",
    "                'ContactPhone': accounts_df.loc[accounts_df['AccountID'] == account, 'Phone'].iloc[0],\n",
    "            })\n",
    "    return pd.DataFrame(relationships)\n",
    "\n",
    "\n",
    "def generate_portfolios(df_accounts, max_positions=10, instruments=[]):\n",
    "    portfolio_records = []\n",
    "\n",
    "    for _, row in df_accounts.iterrows():\n",
    "        AccountId = row[\"AccountID\"]\n",
    "        Company = row[\"Company\"]\n",
    "        num_positions = random.randint(5, 10)\n",
    "        positions = random.sample(instruments, num_positions)\n",
    "        for symbol, instrument_type in positions:\n",
    "            portfolio_records.append({\n",
    "                \"AccountID\": AccountId,\n",
    "                \"Company_name\": Company,\n",
    "                \"symbol\": symbol,\n",
    "                \"instrument_type\": instrument_type\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(portfolio_records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465b8b6-a3b2-4f7a-b84b-ec78f0193812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right now companies can only be selected from this list of publicly traded companies \n",
    "# Likely want this to be random instead..\n",
    "clients_company_info = [\n",
    "        {\"Company\": \"Broadcom\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Cisco\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Palantir Technologies\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Fiserv\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Atlassian\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Leidos\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Duolingo\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Logitech\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Celestica\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Dropbox\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Plexus\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Silicon Laboratories\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Mobix Labs\", \"industry\": \"Technology\"},\n",
    "        {\"Company\": \"Mariott\", \"industry\": \"Hospitality\"},\n",
    "        {\"Company\": \"InterContinental Hotels Group\", \"industry\": \"Hospitality\"},\n",
    "        {\"Company\": \"Sonder Holdings\", \"industry\": \"Hospitality\"},\n",
    "        {\"Company\": \"Hyatt Hotels\", \"industry\": \"Hospitality\"},\n",
    "        {\"Company\": \"Royal Caribbean Cruises\", \"industry\": \"Hospitality\"},\n",
    "        {\"Company\": \"UnitedHealth\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Johnson & Johnson\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"AbbVie\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Novo Nordisk\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Abbott Laboratories\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"AstraZeneca\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Merck & Co\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Intuitive Surgical\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Medtronic\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Zoetis\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Humana\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Illumina\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Guardant Health\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Rhythm Pharmaceuticals\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Amedisys\", \"industry\": \"Healthcare\"},\n",
    "        {\"Company\": \"Rivian Automotive\", \"industry\": \"Automotive\"},\n",
    "        {\"Company\": \"Fordy\", \"industry\": \"Automotive\"},\n",
    "        {\"Company\": \"lululemon athletica\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"DICK'S Sporting Goods\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"GameStop Corp\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Texas Roadhouse\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Hasbro\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Mattel\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Wayfair\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Peloton\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Sally Beauty\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Lifetime Brand\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Allbirds\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Walmart\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Tyson Foods\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Sprouts Farmers Market\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Dollar Tree\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Stride\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Spectrum Brands\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Udemy\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Vital Farms\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Graham Holdings Company\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Hims & Hers Health\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Smithfield Foods\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Albertsons Companies\", \"industry\": \"Retail\"},\n",
    "        {\"Company\": \"Albany International\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"IT Tech Packaging\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"Lockheed Martin Corporation\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"Landstar System\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"Hexcel Corporation\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"AeroVironment\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"Matson\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"McGrath RentCorp\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"Mueller Industries\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"Dolby Laboratories\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"ManpowerGroup\", \"industry\": \"Manufacturing\"},\n",
    "        {\"Company\": \"Welltower\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Iron Mountain Incorporated\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Camden Property\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"CubeSmart\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Federal Realty Investment Trust\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Essential Properties Realty\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Compass\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Medical Properties Trust\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Broadstone\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Ladder Capital Corp\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Peakstone Realty Trus\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Fathom Holdings\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Presidio Property Trust\", \"industry\": \"RealEstate\"},\n",
    "        {\"Company\": \"Service Properties Trust\", \"industry\": \"RealEstate\"},\n",
    "    ]\n",
    "\n",
    "stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META', 'JPM', 'V', 'UNH']\n",
    "bonds = ['US10Y', 'US30Y', 'CORP1', 'CORP2', 'MUNI1', 'MUNI2']\n",
    "mutual_funds = ['VFIAX', 'SWPPX', 'FXAIX', 'VTSAX', 'FZROX', 'SPY']\n",
    "# All symbols with types\n",
    "instruments = (\n",
    "    [(sym, 'Stock') for sym in stocks] +\n",
    "    [(sym, 'Bond') for sym in bonds] +\n",
    "    [(sym, 'Mutual Fund') for sym in mutual_funds]\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the tables\n",
    "employees_df = generate_employee_data(num_employees=100, ourcompany_name = 'bankwell')\n",
    "accounts_df = generate_account_data(num_accounts=1000, clients_company = clients_company_info)\n",
    "opportunities_df = generate_opportunity_data(accounts_df, num_opportunities_per_account=3)\n",
    "contacts_df = generate_employee_contact_data(employees_df, accounts_df, num_relationships_per_employee=30)\n",
    "portfolio_df = generate_portfolios(accounts_df, max_positions=10, instruments = instruments)\n",
    "\n",
    "# Print the first few rows of each DataFrame\n",
    "print(\"Employees Data:\")\n",
    "print(employees_df.head())\n",
    "\n",
    "print(\"\\nAccounts Data:\")\n",
    "print(accounts_df.head())\n",
    "\n",
    "print(\"\\nOpportunities Data:\")\n",
    "print(opportunities_df.head())\n",
    "\n",
    "print(\"\\nEmployee-Contact Relationships Data:\")\n",
    "print(contacts_df.head())\n",
    "\n",
    "print(\"\\nPortfolio Info for Each Account\")\n",
    "print(portfolio_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4017b4a-f604-4f1e-ad2f-96a94abd1a9a",
   "metadata": {},
   "source": [
    "# Load to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a0f5c-2668-4a0a-8df9-03e60bc84a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958610f4-5fc5-4bba-9fd9-592458f84226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employees_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabfd37-61ed-492e-92d3-138edfe447a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employees_df.to_sql('employees', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d13245-d916-4a67-b7b7-cdb274fa3cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * from Employees\", con=engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f84525-e56a-418b-be36-eb737d129872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accounts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1b099-8535-4191-9c6c-ca11b84b364e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accounts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb57d3-1f5e-4786-a1d0-ffc173d6faac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accounts_df.to_sql('clients_contact', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c303f-fb30-4b43-a0dc-149b49320546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contacts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c01cb7-21b0-460a-9265-3aceeeada16c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contacts_df.to_sql('client_alignment', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c189b7-511c-4daf-b4be-b4e50db4f093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "portfolio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1eddaf-bb85-4de8-9e61-b140a89ed36e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "portfolio_df.to_sql('portfolio', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c594d7-ee15-4bd6-913d-a483d53853ac",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358be86-2f78-45e1-bf9b-4f0abec72160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM portfolio limit 10\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7929e-e6e7-4bb9-8bd7-aa1ef2765e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM client_alignment limit 10\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98d55d-1dda-4324-ac44-f347dbfff14f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "print(f\"Notebook last execution time: {datetime.datetime.now(pytz.timezone('US/Central')).strftime('%a, %d %B %Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fa61c-b037-4e3c-87f9-0179614722b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-lc_currensee-lc_currensee",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "lc_currensee",
   "language": "python",
   "name": "conda-env-lc_currensee-lc_currensee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
